import os
from llama_index.core import Settings, load_index_from_storage, StorageContext, PropertyGraphIndex
from llama_index.core.query_engine import KnowledgeGraphQueryEngine

from rag_engine import config
from rag_engine.graph_rag.simple_graph_store_with_schema import SimpleGraphStoreWithSchema
from rag_engine.providers import get_llm, get_embed_model

# å…¨å±€ç´¢å¼•ç¼“å­˜
_index_cache = None


def load_graph_index():
    global _index_cache

    if _index_cache:
        return _index_cache

    if not os.path.exists(config.GRAPH_DB_DIR):
        raise FileNotFoundError(f"ç´¢å¼•ç›®å½•ä¸å­˜åœ¨: {config.GRAPH_DB_DIR}")

    required_files = ["docstore.json", "graph_store.json", "index_store.json"]
    missing_files = [f for f in required_files if not os.path.exists(os.path.join(config.GRAPH_DB_DIR, f))]
    if missing_files:
        raise FileNotFoundError(f"ç´¢å¼•æ–‡ä»¶ç¼ºå¤±: {', '.join(missing_files)}")

    Settings.llm = get_llm()
    Settings.embed_model = get_embed_model()

    print(f"ğŸ“‚ ä» {config.GRAPH_DB_DIR} åŠ è½½å­˜å‚¨ä¸Šä¸‹æ–‡...")

    # âœ… å…³é”®ä¿®æ”¹ï¼šç”¨ä½ çš„ SimpleGraphStoreWithSchema æ˜¾å¼åŠ è½½ graph_store
    graph_store = SimpleGraphStoreWithSchema.from_persist_path(
        persist_path=os.path.join(config.GRAPH_DB_DIR, "graph_store.json")
    )

    storage_context = StorageContext.from_defaults(
        persist_dir=config.GRAPH_DB_DIR,
        graph_store=graph_store
    )

    try:
        _index_cache = PropertyGraphIndex(
            [],
            storage_context=storage_context,
            llm=Settings.llm
        )
        print(f"âœ… æˆåŠŸåŠ è½½çŸ¥è¯†å›¾è°±ç´¢å¼•ï¼ŒID: {_index_cache.index_id}")
        return _index_cache
    except Exception as e:
        print(f"âŒ åŠ è½½ç´¢å¼•å¤±è´¥: {str(e)}")
        print("ç›®å½•å†…å®¹:", os.listdir(config.GRAPH_DB_DIR))
        raise


def ask_question(question: str) -> str:
    try:
        print(f"â“ é—®é¢˜: {question}")
        index = load_graph_index()
        query_engine = index.as_query_engine(
            include_text=True,  # åŒ…å«åŸå§‹æ–‡æœ¬
            retriever_mode="hybrid",  # æ··åˆæ£€ç´¢æ¨¡å¼
            verbose=True
        )
        print("ğŸ” æ­£åœ¨æŸ¥è¯¢...")
        response = query_engine.query(question)
        return str(response)
    except Exception as e:
        return f"æŸ¥è¯¢å¤±è´¥: {str(e)}"
